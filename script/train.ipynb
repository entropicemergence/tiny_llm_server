{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a1b8972-afc0-4253-9414-87833463bc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import tokenizer_basic\n",
    "import transformer_tiny\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99c1b23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53fa724e-63a0-400f-87d3-ab9760d5a8d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\SE\\\\AI general\\\\Dataset\\\\TinyStories\\\\TinyStoriesV2-GPT4-valid.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m tiny_stories\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m      2\u001b[0m tstxt\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSE\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAI general\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mTinyStories\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mTinyStoriesV2-GPT4-train.txt\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSE\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAI general\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mTinyStories\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mTinyStoriesV2-GPT4-valid.txt\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(tstxt[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# for j in range (100):\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     a\u001b[38;5;241m=\u001b[39mfile\u001b[38;5;241m.\u001b[39mreadline()\n\u001b[0;32m      7\u001b[0m     story\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\rtc\\anaconda3\\envs\\ai1\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\SE\\\\AI general\\\\Dataset\\\\TinyStories\\\\TinyStoriesV2-GPT4-valid.txt'"
     ]
    }
   ],
   "source": [
    "tiny_stories=[]\n",
    "tstxt=[r'D:\\SE\\AI general\\Dataset\\TinyStories\\TinyStoriesV2-GPT4-train.txt',r'D:\\SE\\AI general\\Dataset\\TinyStories\\TinyStoriesV2-GPT4-valid.txt']\n",
    "\n",
    "with open(tstxt[1], 'r', encoding='utf-8') as file:\n",
    "    # for j in range (100):\n",
    "    a=file.readline()\n",
    "    story=\"\"\n",
    "    while a:\n",
    "        if a!=\"<|endoftext|>\\n\":\n",
    "            story+=a\n",
    "        else:\n",
    "            tiny_stories.append(story)\n",
    "            story=\"\"\n",
    "        # print (str(a))\n",
    "        a=file.readline()\n",
    "\n",
    "# tiny_stories.sort(key=len)\n",
    "print (len(tiny_stories))\n",
    "for j in range (2):\n",
    "    print (tiny_stories[random.randint(0,len(tiny_stories))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c7fa75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary loaded from tinystories_tokenizer_vocab.json\n",
      "\n",
      "Tokenizer trained successfully!\n",
      "Total vocabulary size: 3266\n",
      "Word vocabulary: 3206 tokens\n",
      "Character vocabulary: 60 characters\n"
     ]
    }
   ],
   "source": [
    "# Create and train the tokenizer\n",
    "tokenizer = tokenizer_basic.HybridTokenizer(vocab_size=3200)\n",
    "\n",
    "tokenizer.load_vocab(\"tinystories_tokenizer_vocab.json\")\n",
    "# Build vocabulary from the loaded stories\n",
    "# tokenizer.build_vocab(tiny_stories)\n",
    "\n",
    "print(f\"\\nTokenizer trained successfully!\")\n",
    "print(f\"Total vocabulary size: {tokenizer.get_vocab_size()}\")\n",
    "print(f\"Word vocabulary: {len(tokenizer.word_to_id)} tokens\")\n",
    "print(f\"Character vocabulary: {len(tokenizer.char_to_id)} characters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2709fd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TOKENIZER TESTING ===\n",
      "\n",
      "Original text: u don't have to be scared of the loud dog, I'll protect you\". The mole felt so safe with the little girl. She was very kind and the mole soon came to trust her. He leaned against her and she kept him safe. The mole had found his best friend.\n",
      "\n",
      "\n",
      "Encoded IDs: [2, 4, 3248, 5, 182, 24, 76, 86, 11, 66, 134, 38, 7, 280, 67, 8, 34, 24, 822, 1202, 27, 12, 6, 7, 1579, 105, 45, 241, 19, 7, 44, 70, 6, 17, 13, 39, 215, 9, 7, 1579, 238, 108, 11, 1386, 23, 6, 15, 2326, 2079, 23, 9, 17, 344, 75, 241, 6, 7, 1579, 31, 88, 22, 167, 93, 6, 3]\n",
      "Sequence length: 65\n",
      "\n",
      "Decoded text: u don ' t have to be scared of the loud dog , i ' ll protect you \" . the mole felt so safe with the little girl . she was very kind and the mole soon came to trust her . he leaned against her and she kept him safe . the mole had found his best friend .\n",
      "\n",
      "Test with rare words: The xylophone played melodious symphonies while extraordinary creatures danced.\n",
      "Encoded: [2, 7, 4, 3251, 3252, 3239, 3242, 3243, 3235, 3242, 3241, 3232, 5, 71, 4, 3240, 3232, 3239, 3242, 3231, 3236, 3242, 3248, 3246, 5, 4, 3246, 3252, 3240, 3243, 3235, 3242, 3241, 3236, 3232, 3246, 5, 229, 4, 3232, 3251, 3247, 3245, 3228, 3242, 3245, 3231, 3236, 3241, 3228, 3245, 3252, 5, 2924, 609, 6, 3]\n",
      "Decoded: the xylophone played melodious symphonies while extraordinary creatures danced .\n",
      "\n",
      "=== WORD vs CHARACTER ENCODING EXAMPLES ===\n",
      "'the' -> [7] (WORD)\n",
      "'and' -> [9] (WORD)\n",
      "'was' -> [13] (WORD)\n",
      "'xylophone' -> [4, 3251, 3252, 3239, 3242, 3243, 3235, 3242, 3241, 3232, 5] (CHAR)\n",
      "'extraordinary' -> [4, 3232, 3251, 3247, 3245, 3228, 3242, 3245, 3231, 3236, 3241, 3228, 3245, 3252, 5] (CHAR)\n",
      "'symphonies' -> [4, 3246, 3252, 3240, 3243, 3235, 3242, 3241, 3236, 3232, 3246, 5] (CHAR)\n",
      "\n",
      "=== PYTORCH BATCH ENCODING ===\n",
      "Batch input_ids shape: torch.Size([3, 20])\n",
      "Batch attention_mask shape: torch.Size([3, 20])\n",
      "First sequence: [2, 56, 59, 10, 49, 8, 46, 13, 10, 44, 70, 6, 3, 0, 0, 0, 0, 0, 0, 0]\n",
      "First attention mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "=== VOCABULARY STATISTICS ===\n",
      "Most frequent words (top 10):\n",
      "  6: '.'\n",
      "  7: 'the'\n",
      "  8: ','\n",
      "  9: 'and'\n",
      "  10: 'a'\n",
      "  11: 'to'\n",
      "  12: '\"'\n",
      "  13: 'was'\n",
      "  14: 'they'\n",
      "  15: 'he'\n",
      "\n",
      "Special tokens:\n",
      "  0: <PAD>\n",
      "  1: <UNK>\n",
      "  2: <BOS>\n",
      "  3: <EOS>\n",
      "  4: <CHAR_START>\n",
      "  5: <CHAR_END>\n",
      "\n",
      "Character vocabulary (first 20):\n",
      "  3206: !\n",
      "  3207: \"\n",
      "  3208: '\n",
      "  3209: ,\n",
      "  3210: -\n",
      "  3211: .\n",
      "  3212: /\n",
      "  3213: 0\n",
      "  3214: 1\n",
      "  3215: 2\n",
      "  3216: 3\n",
      "  3217: 4\n",
      "  3218: 5\n",
      "  3219: 6\n",
      "  3220: 7\n",
      "  3221: 8\n",
      "  3222: 9\n",
      "  3223: :\n",
      "  3224: ;\n",
      "  3225: =\n"
     ]
    }
   ],
   "source": [
    "# Test the tokenizer with sample stories\n",
    "print(\"=== TOKENIZER TESTING ===\\n\")\n",
    "\n",
    "# Test with a sample story\n",
    "test_story = tiny_stories[0]  # First 200 chars of first story\n",
    "print(f\"Original text: {test_story}\")\n",
    "print()\n",
    "\n",
    "# Encode the story\n",
    "encoded = tokenizer.encode(test_story)\n",
    "print(f\"Encoded IDs: {encoded}\")\n",
    "print(f\"Sequence length: {len(encoded)}\")\n",
    "print()\n",
    "\n",
    "# Decode back to text\n",
    "decoded = tokenizer.decode(encoded)\n",
    "print(f\"Decoded text: {decoded}\")\n",
    "print()\n",
    "\n",
    "# Test with a sentence containing rare words\n",
    "test_rare = \"The xylophone played melodious symphonies while extraordinary creatures danced.\"\n",
    "print(f\"Test with rare words: {test_rare}\")\n",
    "encoded_rare = tokenizer.encode(test_rare)\n",
    "print(f\"Encoded: {encoded_rare}\")\n",
    "decoded_rare = tokenizer.decode(encoded_rare)\n",
    "print(f\"Decoded: {decoded_rare}\")\n",
    "print()\n",
    "\n",
    "# Show some examples of word vs character encoding\n",
    "print(\"=== WORD vs CHARACTER ENCODING EXAMPLES ===\")\n",
    "test_words = [\"the\", \"and\", \"was\", \"xylophone\", \"extraordinary\", \"symphonies\"]\n",
    "for word in test_words:\n",
    "    encoded_word = tokenizer.encode_word_or_chars(word)\n",
    "    is_word_level = len(encoded_word) == 1 and encoded_word[0] < len(tokenizer.word_to_id)\n",
    "    encoding_type = \"WORD\" if is_word_level else \"CHAR\"\n",
    "    print(f\"'{word}' -> {encoded_word} ({encoding_type})\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Test batch encoding for PyTorch\n",
    "print(\"=== PYTORCH BATCH ENCODING ===\")\n",
    "test_batch = [\n",
    "    \"Once upon a time, there was a little girl.\",\n",
    "    \"She loved to play with her toys.\",\n",
    "    \"The end.\"\n",
    "]\n",
    "\n",
    "batch_encoded = tokenizer.encode_batch(test_batch, max_length=20, padding=True)\n",
    "print(f\"Batch input_ids shape: {batch_encoded['input_ids'].shape}\")\n",
    "print(f\"Batch attention_mask shape: {batch_encoded['attention_mask'].shape}\")\n",
    "print(f\"First sequence: {batch_encoded['input_ids'][0].tolist()}\")\n",
    "print(f\"First attention mask: {batch_encoded['attention_mask'][0].tolist()}\")\n",
    "\n",
    "# Show vocabulary statistics\n",
    "print(f\"\\n=== VOCABULARY STATISTICS ===\")\n",
    "print(f\"Most frequent words (top 10):\")\n",
    "word_items = [(word, idx) for word, idx in tokenizer.word_to_id.items() \n",
    "              if word not in tokenizer.special_tokens]\n",
    "word_items_sorted = sorted(word_items, key=lambda x: x[1])[:10]\n",
    "for word, idx in word_items_sorted:\n",
    "    print(f\"  {idx}: '{word}'\")\n",
    "\n",
    "print(f\"\\nSpecial tokens:\")\n",
    "for token, idx in tokenizer.special_tokens.items():\n",
    "    print(f\"  {idx}: {token}\")\n",
    "\n",
    "print(f\"\\nCharacter vocabulary (first 20):\")\n",
    "char_items = sorted(tokenizer.char_to_id.items(), key=lambda x: x[1])[:20]\n",
    "for char, idx in char_items:\n",
    "    display_char = repr(char) if char in ['\\n', '\\t', ' '] else char\n",
    "    print(f\"  {idx + len(tokenizer.word_to_id)}: {display_char}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3c697f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary saved to tinystories_tokenizer_vocab.json\n"
     ]
    }
   ],
   "source": [
    "# Save the tokenizer vocabulary\n",
    "tokenizer.save_vocab(\"tinystories_tokenizer_vocab.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03685ee-8279-42fb-97ac-dca6451d48bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53687692-bac9-41fd-aa15-0a4d9ed598f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created with 27630 stories\n",
      "Sample input_ids shape: torch.Size([64])\n",
      "Sample labels shape: torch.Size([64])\n",
      "\n",
      "Batch shapes:\n",
      "input_ids: torch.Size([32, 490])\n",
      "labels: torch.Size([32, 490])\n",
      "attention_mask: torch.Size([32, 490])\n",
      "\n",
      "=== TOKENIZER READY FOR TRAINING ===\n",
      "Vocabulary size: 3266\n",
      "Word-level tokens: 3206\n",
      "Character-level tokens: 60\n",
      "Dataset ready with 27630 samples\n",
      "DataLoader ready with batch size 4\n",
      "\n",
      "=== EXAMPLE: LOADING SAVED TOKENIZER ===\n",
      "Vocabulary loaded from tinystories_tokenizer_vocab.json\n",
      "Loaded tokenizer with vocab size: 3266\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Example: Create a PyTorch Dataset class for training\n",
    "class TinyStoriesDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, stories, tokenizer, max_length=512):\n",
    "        self.stories = stories\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.stories)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        story = self.stories[idx]\n",
    "        \n",
    "        # Encode the story\n",
    "        encoded = self.tokenizer.encode(story, add_special_tokens=True)\n",
    "        \n",
    "        # Truncate if too long\n",
    "        if len(encoded) > self.max_length:\n",
    "            encoded = encoded[:self.max_length]\n",
    "        \n",
    "        # For language modeling, input is sequence[:-1] and target is sequence[1:]\n",
    "        input_ids = encoded[:-1] if len(encoded) > 1 else [self.tokenizer.pad_id]\n",
    "        labels = encoded[1:] if len(encoded) > 1 else [self.tokenizer.pad_id]\n",
    "        \n",
    "        return {\n",
    "            'input_ids': torch.tensor(input_ids, dtype=torch.long),\n",
    "            'labels': torch.tensor(labels, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Create dataset\n",
    "dataset = TinyStoriesDataset(tiny_stories, tokenizer, max_length=512)  # First 1000 stories\n",
    "print(f\"Dataset created with {len(dataset)} stories\")\n",
    "# print(dataset[0])\n",
    "\n",
    "# Test dataset\n",
    "sample = dataset[0]\n",
    "print(f\"Sample input_ids shape: {sample['input_ids'].shape}\")\n",
    "print(f\"Sample labels shape: {sample['labels'].shape}\")\n",
    "\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # Pad sequences in batch\n",
    "    input_ids = [item['input_ids'] for item in batch]\n",
    "    labels = [item['labels'] for item in batch]\n",
    "    \n",
    "    # Pad to max length in batch\n",
    "    max_len = max(len(seq) for seq in input_ids)\n",
    "    \n",
    "    padded_inputs = []\n",
    "    padded_labels = []\n",
    "    attention_masks = []\n",
    "    \n",
    "    for i in range(len(input_ids)):\n",
    "        seq_len = len(input_ids[i])\n",
    "        \n",
    "        # Pad input_ids\n",
    "        padded_input = torch.cat([\n",
    "            input_ids[i],\n",
    "            torch.full((max_len - seq_len,), tokenizer.pad_id, dtype=torch.long)\n",
    "        ])\n",
    "        \n",
    "        # Pad labels  \n",
    "        padded_label = torch.cat([\n",
    "            labels[i],\n",
    "            torch.full((max_len - seq_len,), -100, dtype=torch.long)  # -100 is ignored in loss\n",
    "        ])\n",
    "        \n",
    "        # Create attention mask\n",
    "        attention_mask = torch.cat([\n",
    "            torch.ones(seq_len, dtype=torch.long),\n",
    "            torch.zeros(max_len - seq_len, dtype=torch.long)\n",
    "        ])\n",
    "        \n",
    "        padded_inputs.append(padded_input)\n",
    "        padded_labels.append(padded_label)\n",
    "        attention_masks.append(attention_mask)\n",
    "    \n",
    "    return {\n",
    "        'input_ids': torch.stack(padded_inputs),\n",
    "        'labels': torch.stack(padded_labels),\n",
    "        'attention_mask': torch.stack(attention_masks)\n",
    "    }\n",
    "\n",
    "# Create DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# Test batch\n",
    "batch = next(iter(dataloader))\n",
    "print(f\"\\nBatch shapes:\")\n",
    "print(f\"input_ids: {batch['input_ids'].shape}\")\n",
    "print(f\"labels: {batch['labels'].shape}\")\n",
    "print(f\"attention_mask: {batch['attention_mask'].shape}\")\n",
    "\n",
    "print(f\"\\n=== TOKENIZER READY FOR TRAINING ===\")\n",
    "print(f\"Vocabulary size: {tokenizer.get_vocab_size()}\")\n",
    "print(f\"Word-level tokens: {len(tokenizer.word_to_id)}\")\n",
    "print(f\"Character-level tokens: {len(tokenizer.char_to_id)}\")\n",
    "print(f\"Dataset ready with {len(dataset)} samples\")\n",
    "print(f\"DataLoader ready with batch size 4\")\n",
    "\n",
    "# Example of loading the tokenizer later\n",
    "print(f\"\\n=== EXAMPLE: LOADING SAVED TOKENIZER ===\")\n",
    "new_tokenizer = tokenizer_basic.HybridTokenizer()\n",
    "new_tokenizer.load_vocab(\"tinystories_tokenizer_vocab.json\")\n",
    "print(f\"Loaded tokenizer with vocab size: {new_tokenizer.get_vocab_size()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1bf1b1c-138a-499a-b7c4-bffeff216b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TinyTransformer(\n",
      "  (token_embedding): Embedding(3266, 192)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (blocks): ModuleList(\n",
      "    (0-5): 6 x Block(\n",
      "      (sa): MultiHeadAttention(\n",
      "        (heads): ModuleList(\n",
      "          (0-5): 6 x Head(\n",
      "            (key): Linear(in_features=192, out_features=32, bias=False)\n",
      "            (query): Linear(in_features=192, out_features=32, bias=False)\n",
      "            (value): Linear(in_features=192, out_features=32, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (proj): Linear(in_features=192, out_features=192, bias=False)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ffwd): FeedForward(\n",
      "        (net): Sequential(\n",
      "          (0): Linear(in_features=192, out_features=768, bias=False)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=768, out_features=192, bias=False)\n",
      "          (3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (ln1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "      (ln2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (ln_f): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "  (lm_head): Linear(in_features=192, out_features=3266, bias=False)\n",
      ")\n",
      "Total parameters: 3,913,344\n"
     ]
    }
   ],
   "source": [
    "tiny_transformer=transformer_tiny.TinyTransformer(\n",
    "    vocab_size=tokenizer.get_vocab_size(),\n",
    "    n_embd=192,\n",
    "    n_head=6,\n",
    "    n_layer=6,\n",
    "    max_context=512,\n",
    "    dropout=0.1\n",
    ")\n",
    "print(tiny_transformer)\n",
    "total_params = sum(p.numel() for p in tiny_transformer.parameters())\n",
    "print(f\"Total parameters: {total_params:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22b2ad49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(\"final_model.pth\")\n",
    "tiny_transformer.load_state_dict(torch.load(\"final_model.pth\")['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a987e57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f41183-526a-4ee9-9d28-6d71e7076c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Starting training for 3 epochs...\n",
      "Total batches per epoch: 864\n",
      "Learning rate: 0.0003\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 864/864 [05:32<00:00,  2.60it/s, Loss=3.4320, Avg Loss=4.3443, LR=3.00e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/3 Summary:\n",
      "  Average Loss: 4.3443\n",
      "  Time: 332.13s\n",
      "  Batches processed: 864\n",
      "  ✓ New best model saved! Loss: 4.3443\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 864/864 [08:33<00:00,  1.68it/s, Loss=2.9764, Avg Loss=3.2588, LR=3.00e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/3 Summary:\n",
      "  Average Loss: 3.2588\n",
      "  Time: 513.34s\n",
      "  Batches processed: 864\n",
      "  ✓ New best model saved! Loss: 3.2588\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 864/864 [05:56<00:00,  2.43it/s, Loss=2.8641, Avg Loss=2.9037, LR=3.00e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/3 Summary:\n",
      "  Average Loss: 2.9037\n",
      "  Time: 356.28s\n",
      "  Batches processed: 864\n",
      "  ✓ New best model saved! Loss: 2.9037\n",
      "--------------------------------------------------\n",
      "\n",
      "🎉 Training completed!\n",
      "Final average loss: 2.8641\n",
      "Best loss achieved: 2.9037\n",
      "Total training samples processed: 2592\n",
      "Final model saved as 'final_model.pth'\n"
     ]
    }
   ],
   "source": [
    "# Training configuration\n",
    "num_epochs = 3\n",
    "learning_rate = 3e-4\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Move model to device\n",
    "tiny_transformer = tiny_transformer.to(device)\n",
    "\n",
    "# Setup optimizer and loss function\n",
    "optimizer = torch.optim.AdamW(tiny_transformer.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-100)  # -100 tokens are ignored\n",
    "\n",
    "# Training statistics\n",
    "train_losses = []\n",
    "best_loss = float('inf')\n",
    "\n",
    "print(f\"Starting training for {num_epochs} epochs...\")\n",
    "print(f\"Total batches per epoch: {len(dataloader)}\")\n",
    "print(f\"Learning rate: {learning_rate}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    tiny_transformer.train()\n",
    "    epoch_losses = []\n",
    "    epoch_start_time = time.time()\n",
    "    \n",
    "    # Progress bar for the epoch\n",
    "    pbar = tqdm(dataloader, desc=f'Epoch {epoch+1}/{num_epochs}', \n",
    "                leave=True, dynamic_ncols=True)\n",
    "    \n",
    "    for batch_idx, batch in enumerate(pbar):\n",
    "        # Move batch to device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Get model outputs (logits)\n",
    "        outputs = tiny_transformer(input_ids)  # Shape: [batch_size, seq_len, vocab_size]\n",
    "        \n",
    "        # Reshape for loss calculation\n",
    "        # outputs: [batch_size * seq_len, vocab_size]\n",
    "        # labels: [batch_size * seq_len]\n",
    "        loss = criterion(outputs.reshape(-1, outputs.size(-1)), labels.reshape(-1))\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping to prevent exploding gradients\n",
    "        torch.nn.utils.clip_grad_norm_(tiny_transformer.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track loss\n",
    "        current_loss = loss.item()\n",
    "        epoch_losses.append(current_loss)\n",
    "        train_losses.append(current_loss)\n",
    "        \n",
    "        # Update progress bar\n",
    "        avg_loss = sum(epoch_losses) / len(epoch_losses)\n",
    "        pbar.set_postfix({\n",
    "            'Loss': f'{current_loss:.4f}',\n",
    "            'Avg Loss': f'{avg_loss:.4f}',\n",
    "            'LR': f'{learning_rate:.2e}'\n",
    "        })\n",
    "        \n",
    "        # Removed frequent batch logging to keep progress bar clean\n",
    "        # All relevant info (Loss, Avg Loss, LR) is shown in the progress bar\n",
    "    \n",
    "    # End of epoch statistics\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    avg_epoch_loss = sum(epoch_losses) / len(epoch_losses)\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs} Summary:\")\n",
    "    print(f\"  Average Loss: {avg_epoch_loss:.4f}\")\n",
    "    print(f\"  Time: {epoch_time:.2f}s\")\n",
    "    print(f\"  Batches processed: {len(epoch_losses)}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if avg_epoch_loss < best_loss:\n",
    "        best_loss = avg_epoch_loss\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': tiny_transformer.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': best_loss,\n",
    "            'vocab_size': tokenizer.get_vocab_size(),\n",
    "        }, 'best_model.pth')\n",
    "        print(f\"  ✓ New best model saved! Loss: {best_loss:.4f}\")\n",
    "    \n",
    "    print(\"-\" * 50)\n",
    "\n",
    "print(f\"\\n🎉 Training completed!\")\n",
    "print(f\"Final average loss: {train_losses[-1]:.4f}\")\n",
    "print(f\"Best loss achieved: {best_loss:.4f}\")\n",
    "print(f\"Total training samples processed: {len(train_losses)}\")\n",
    "\n",
    "# Save final model\n",
    "torch.save({\n",
    "    'epoch': num_epochs,\n",
    "    'model_state_dict': tiny_transformer.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': train_losses[-1],\n",
    "    'vocab_size': tokenizer.get_vocab_size(),\n",
    "    'train_losses': train_losses,\n",
    "}, 'final_model2.pth')\n",
    "print(\"Final model saved as 'final_model.pth'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f4fa682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training statistics:\n",
      "  Initial loss: 8.1318\n",
      "  Final loss: 2.8641\n",
      "  Best loss: 2.9037\n",
      "  Loss improvement: 5.2677\n",
      "  Relative improvement: 64.78%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if len(train_losses) > 0:\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Plot 1: Raw loss over batches\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, alpha=0.7, linewidth=0.8)\n",
    "    plt.title('Training Loss Over Batches')\n",
    "    plt.xlabel('Batch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Smoothed loss (moving average)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    window_size = min(50, len(train_losses) // 10)  # Adaptive window size\n",
    "    if window_size > 1:\n",
    "        smoothed_loss = np.convolve(train_losses, np.ones(window_size)/window_size, mode='valid')\n",
    "        plt.plot(range(window_size-1, len(train_losses)), smoothed_loss, color='red', linewidth=2)\n",
    "        plt.title(f'Smoothed Training Loss (window={window_size})')\n",
    "    else:\n",
    "        plt.plot(train_losses, color='red', linewidth=2)\n",
    "        plt.title('Training Loss')\n",
    "    \n",
    "    plt.xlabel('Batch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_progress.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Training statistics:\")\n",
    "    print(f\"  Initial loss: {train_losses[0]:.4f}\")\n",
    "    print(f\"  Final loss: {train_losses[-1]:.4f}\")\n",
    "    print(f\"  Best loss: {best_loss:.4f}\")\n",
    "    print(f\"  Loss improvement: {train_losses[0] - train_losses[-1]:.4f}\")\n",
    "    print(f\"  Relative improvement: {((train_losses[0] - train_losses[-1]) / train_losses[0] * 100):.2f}%\")\n",
    "else:\n",
    "    print(\"No training losses to plot. Run the training cell first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfa9beb6-281e-4b97-bf42-789943e94d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: 'this morning i walk'\n",
      "Encoded prompt: [2, 139, 730, 34, 284, 3]\n",
      "Generating 128 new tokens...\n",
      "==================================================\n",
      "Streaming generation:\n",
      "Starting with: 'this morning i walk'\n",
      "\n",
      "Generated tokens:\n",
      "Step   1: Token ID    6 -> '.'\n",
      "Step   2: Token ID   16 -> 'it'\n",
      "Step   3: Token ID   13 -> 'was'\n",
      "Step   4: Token ID   10 -> 'a'\n",
      "Step   5: Token ID   28 -> 'big'\n",
      "Step   6: Token ID    8 -> ','\n",
      "Step   7: Token ID  594 -> 'round'\n",
      "Step   8: Token ID  200 -> 'sun'\n",
      "Step   9: Token ID    6 -> '.'\n",
      "Step  10: Token ID   16 -> 'it'\n",
      "Step  11: Token ID   13 -> 'was'\n",
      "Step  12: Token ID   10 -> 'a'\n",
      "Step  13: Token ID   28 -> 'big'\n",
      "Step  14: Token ID    8 -> ','\n",
      "Step  15: Token ID  161 -> 'red'\n",
      "Step  16: Token ID   77 -> 'ball'\n",
      "Step  17: Token ID    6 -> '.'\n",
      "Step  18: Token ID   16 -> 'it'\n",
      "Step  19: Token ID   13 -> 'was'\n",
      "Step  20: Token ID   10 -> 'a'\n",
      "Step  21: Token ID   28 -> 'big'\n",
      "Step  22: Token ID    8 -> ','\n",
      "Step  23: Token ID  161 -> 'red'\n",
      "Step  24: Token ID   77 -> 'ball'\n",
      "Step  25: Token ID    6 -> '.'\n",
      "Step  26: Token ID    7 -> 'the'\n",
      "Step  27: Token ID   77 -> 'ball'\n",
      "Step  28: Token ID   13 -> 'was'\n",
      "Step  29: Token ID   39 -> 'very'\n",
      "Step  30: Token ID   37 -> 'happy'\n",
      "Step  31: Token ID    6 -> '.'\n",
      "Step  32: Token ID    7 -> 'the'\n",
      "Step  33: Token ID   77 -> 'ball'\n",
      "Step  34: Token ID   52 -> 'wanted'\n",
      "Step  35: Token ID   11 -> 'to'\n",
      "Step  36: Token ID   43 -> 'play'\n",
      "Step  37: Token ID   19 -> 'with'\n",
      "Step  38: Token ID   16 -> 'it'\n",
      "Step  39: Token ID    6 -> '.'\n",
      "Step  40: Token ID    7 -> 'the'\n",
      "Step  41: Token ID   77 -> 'ball'\n",
      "Step  42: Token ID   13 -> 'was'\n",
      "Step  43: Token ID   39 -> 'very'\n",
      "Step  44: Token ID   37 -> 'happy'\n",
      "Step  45: Token ID    6 -> '.'\n",
      "Step  46: Token ID    7 -> 'the'\n",
      "Step  47: Token ID   77 -> 'ball'\n",
      "Step  48: Token ID   52 -> 'wanted'\n",
      "Step  49: Token ID   11 -> 'to'\n",
      "Step  50: Token ID   43 -> 'play'\n",
      "Step  51: Token ID   19 -> 'with'\n",
      "Step  52: Token ID    7 -> 'the'\n",
      "Step  53: Token ID   77 -> 'ball'\n",
      "Step  54: Token ID    6 -> '.'\n",
      "Step  55: Token ID    7 -> 'the'\n",
      "Step  56: Token ID   77 -> 'ball'\n",
      "Step  57: Token ID   13 -> 'was'\n",
      "Step  58: Token ID   39 -> 'very'\n",
      "Step  59: Token ID   37 -> 'happy'\n",
      "Step  60: Token ID    6 -> '.'\n",
      "Step  61: Token ID    7 -> 'the'\n",
      "Step  62: Token ID   77 -> 'ball'\n",
      "Step  63: Token ID   31 -> 'had'\n",
      "Step  64: Token ID   10 -> 'a'\n",
      "Step  65: Token ID   77 -> 'ball'\n",
      "Step  66: Token ID    6 -> '.'\n",
      "Step  67: Token ID    7 -> 'the'\n",
      "Step  68: Token ID   77 -> 'ball'\n",
      "Step  69: Token ID   13 -> 'was'\n",
      "Step  70: Token ID   37 -> 'happy'\n",
      "Step  71: Token ID    6 -> '.'\n",
      "Step  72: Token ID    7 -> 'the'\n",
      "Step  73: Token ID   77 -> 'ball'\n",
      "Step  74: Token ID   13 -> 'was'\n",
      "Step  75: Token ID   37 -> 'happy'\n",
      "Step  76: Token ID    6 -> '.'\n",
      "Step  77: Token ID    7 -> 'the'\n",
      "Step  78: Token ID   77 -> 'ball'\n",
      "Step  79: Token ID   13 -> 'was'\n",
      "Step  80: Token ID   37 -> 'happy'\n",
      "Step  81: Token ID    6 -> '.'\n",
      "Step  82: Token ID    7 -> 'the'\n",
      "Step  83: Token ID   77 -> 'ball'\n",
      "Step  84: Token ID   13 -> 'was'\n",
      "Step  85: Token ID   37 -> 'happy'\n",
      "Step  86: Token ID    6 -> '.'\n",
      "Step  87: Token ID    7 -> 'the'\n",
      "Step  88: Token ID   77 -> 'ball'\n",
      "Step  89: Token ID   13 -> 'was'\n",
      "Step  90: Token ID   37 -> 'happy'\n",
      "Step  91: Token ID    6 -> '.'\n",
      "Step  92: Token ID    7 -> 'the'\n",
      "Step  93: Token ID   77 -> 'ball'\n",
      "Step  94: Token ID   13 -> 'was'\n",
      "Step  95: Token ID   37 -> 'happy'\n",
      "Step  96: Token ID    6 -> '.'\n",
      "Step  97: Token ID    7 -> 'the'\n",
      "Step  98: Token ID   77 -> 'ball'\n",
      "Step  99: Token ID   13 -> 'was'\n",
      "Step 100: Token ID   37 -> 'happy'\n",
      "Step 101: Token ID    6 -> '.'\n",
      "Step 102: Token ID    7 -> 'the'\n",
      "Step 103: Token ID   77 -> 'ball'\n",
      "Step 104: Token ID   13 -> 'was'\n",
      "Step 105: Token ID   37 -> 'happy'\n",
      "Step 106: Token ID    6 -> '.'\n",
      "Step 107: Token ID    7 -> 'the'\n",
      "Step 108: Token ID   77 -> 'ball'\n",
      "Step 109: Token ID   13 -> 'was'\n",
      "Step 110: Token ID   37 -> 'happy'\n",
      "Step 111: Token ID    6 -> '.'\n",
      "Step 112: Token ID    7 -> 'the'\n",
      "Step 113: Token ID   77 -> 'ball'\n",
      "Step 114: Token ID   13 -> 'was'\n",
      "Step 115: Token ID   37 -> 'happy'\n",
      "Step 116: Token ID    6 -> '.'\n",
      "Step 117: Token ID    7 -> 'the'\n",
      "Step 118: Token ID   77 -> 'ball'\n",
      "Step 119: Token ID   13 -> 'was'\n",
      "Step 120: Token ID   37 -> 'happy'\n",
      "Step 121: Token ID    6 -> '.'\n",
      "Step 122: Token ID    7 -> 'the'\n",
      "Step 123: Token ID   77 -> 'ball'\n",
      "Step 124: Token ID   13 -> 'was'\n",
      "Step 125: Token ID   37 -> 'happy'\n",
      "Step 126: Token ID    6 -> '.'\n",
      "Step 127: Token ID    3 -> '<EOS>'\n",
      "End of sequence token generated!\n",
      "\n",
      "==================================================\n",
      "Generation complete!\n",
      "Full generated text: 'this morning i walk . it was a big , round sun . it was a big , red ball . it was a big , red ball . the ball was very happy . the ball wanted to play with it . the ball was very happy . the ball wanted to play with the ball . the ball was very happy . the ball had a ball . the ball was happy . the ball was happy . the ball was happy . the ball was happy . the ball was happy . the ball was happy . the ball was happy . the ball was happy . the ball was happy . the ball was happy . the ball was happy . the ball was happy .'\n",
      "Original prompt: 'this morning i walk'\n",
      "Generated continuation: '. it was a big , round sun . it was a big , red ball . it was a big , red ball . the ball was very happy . the ball wanted to play with it . the ball was very happy . the ball wanted to play with the ball . the ball was very happy . the ball had a ball . the ball was happy . the ball was happy . the ball was happy . the ball was happy . the ball was happy . the ball was happy . the ball was happy . the ball was happy . the ball was happy . the ball was happy . the ball was happy . the ball was happy .'\n",
      "Total tokens generated: 127\n"
     ]
    }
   ],
   "source": [
    "prompt = \"this morning i walk\"\n",
    "max_token = 128\n",
    "\n",
    "# Set model to evaluation mode\n",
    "tiny_transformer.eval()\n",
    "\n",
    "# Encode the prompt\n",
    "prompt_ids = tokenizer.encode(prompt, add_special_tokens=True)\n",
    "print(f\"Prompt: '{prompt}'\")\n",
    "print(f\"Encoded prompt: {prompt_ids}\")\n",
    "\n",
    "# Convert to tensor and add batch dimension\n",
    "input_ids = torch.tensor(prompt_ids, dtype=torch.long).unsqueeze(0)  # Shape: [1, seq_len]\n",
    "\n",
    "# Move to device if using GPU\n",
    "device = next(tiny_transformer.parameters()).device\n",
    "input_ids = input_ids.to(device)\n",
    "\n",
    "print(f\"Generating {max_token} new tokens...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Generation parameters\n",
    "temperature = 0.0\n",
    "top_k = 50\n",
    "\n",
    "# Keep track of generated tokens\n",
    "generated_tokens = []\n",
    "current_sequence = input_ids.clone()\n",
    "\n",
    "print(\"Streaming generation:\")\n",
    "print(f\"Starting with: '{tokenizer.decode(current_sequence[0].tolist())}'\")\n",
    "print(\"\\nGenerated tokens:\")\n",
    "\n",
    "# Generate tokens one by one\n",
    "with torch.no_grad():\n",
    "    for step in range(max_token):\n",
    "        # Crop sequence to max context if needed\n",
    "        if current_sequence.size(1) > tiny_transformer.max_context:\n",
    "            current_sequence = current_sequence[:, -tiny_transformer.max_context:]\n",
    "        \n",
    "        # Forward pass to get logits\n",
    "        logits = tiny_transformer(current_sequence)  # Shape: [1, seq_len, vocab_size]\n",
    "        \n",
    "        # Get logits for the last position (next token prediction)\n",
    "        next_token_logits = logits[:, -1, :]  # Shape: [1, vocab_size]\n",
    "        \n",
    "        # Handle different sampling strategies\n",
    "        if temperature == 0.0:\n",
    "            # Greedy decoding: choose token with highest logit\n",
    "            next_token = torch.argmax(next_token_logits, dim=-1, keepdim=True)  # Shape: [1, 1]\n",
    "        else:\n",
    "            # Temperature sampling\n",
    "            next_token_logits = next_token_logits / temperature\n",
    "            \n",
    "            # Apply top-k filtering\n",
    "            if top_k is not None:\n",
    "                v, _ = torch.topk(next_token_logits, min(top_k, next_token_logits.size(-1)))\n",
    "                next_token_logits[next_token_logits < v[:, [-1]]] = -float('inf')\n",
    "            \n",
    "            # Convert logits to probabilities\n",
    "            probs = torch.softmax(next_token_logits, dim=-1)\n",
    "            \n",
    "            # Sample next token\n",
    "            next_token = torch.multinomial(probs, num_samples=1)  # Shape: [1, 1]\n",
    "        \n",
    "        # Add to sequence\n",
    "        current_sequence = torch.cat([current_sequence, next_token], dim=1)\n",
    "        \n",
    "        # Store the generated token\n",
    "        token_id = next_token[0, 0].item()\n",
    "        generated_tokens.append(token_id)\n",
    "        \n",
    "        # Decode and print the new token\n",
    "        try:\n",
    "            # Try to decode just this token\n",
    "            if token_id in tokenizer.id_to_word:\n",
    "                token_text = tokenizer.id_to_word[token_id]\n",
    "            else:\n",
    "                # For character-level tokens, decode in context\n",
    "                token_text = tokenizer.decode([token_id])\n",
    "            \n",
    "            print(f\"Step {step+1:3d}: Token ID {token_id:4d} -> '{token_text}'\")\n",
    "            \n",
    "            # Check for end of sequence\n",
    "            if token_id == tokenizer.eos_id:\n",
    "                print(\"End of sequence token generated!\")\n",
    "                break\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Step {step+1:3d}: Token ID {token_id:4d} -> [decode error: {e}]\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Generation complete!\")\n",
    "\n",
    "# Decode the full generated sequence\n",
    "full_sequence = current_sequence[0].tolist()\n",
    "full_text = tokenizer.decode(full_sequence)\n",
    "print(f\"Full generated text: '{full_text}'\")\n",
    "\n",
    "# Show just the new part\n",
    "original_length = len(prompt_ids)\n",
    "new_tokens_text = tokenizer.decode(generated_tokens)\n",
    "print(f\"Original prompt: '{prompt}'\")\n",
    "print(f\"Generated continuation: '{new_tokens_text}'\")\n",
    "print(f\"Total tokens generated: {len(generated_tokens)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c9c3ae-02d8-4f38-923b-208590de3cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "814fd91c-0cbb-4f80-bc9e-6059fb756e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights exported to '../model/weights' with metadata.txt for pure C++ loading\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "export_dir = '../model/weights'\n",
    "os.makedirs(export_dir, exist_ok=True)\n",
    "state_dict = tiny_transformer.state_dict()\n",
    "\n",
    "with open(os.path.join(export_dir, 'metadata.txt'), 'w') as f:\n",
    "    for name, tensor in state_dict.items():\n",
    "        np_array = tensor.detach().cpu().numpy().astype(np.float32)\n",
    "        # print (np_array[0][:10])\n",
    "        bin_path = os.path.join(export_dir, name.replace('.', '_') + '.bin')\n",
    "        np_array.tofile(bin_path)\n",
    "        \n",
    "        shape_str = ' '.join(map(str, tensor.shape))\n",
    "        f.write(f\"{name} {shape_str} float32 {np_array.size}\\n\")\n",
    "\n",
    "print(f\"Weights exported to '{export_dir}' with metadata.txt for pure C++ loading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545c89d3-f07b-4953-80fe-1d97f32624c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d987a23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b81b218",
   "metadata": {},
   "source": [
    "# Model Compute Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b05875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered 264 hooks on all layers\n",
      "Input shape: torch.Size([1, 6])\n",
      "Model output shape: torch.Size([1, 6, 3266])\n",
      "Model output sum: -39812.984375\n",
      "\n",
      "================================================================================\n",
      "LAYER ACTIVATIONS ANALYSIS\n",
      "================================================================================\n",
      "Layer: token_embedding                          | Shape: torch.Size([1, 6, 192]) | Sum:   -9.0557632666 | Norm:    3.9818859744\n",
      "Layer: dropout                                  | Shape: torch.Size([1, 6, 192]) | Sum:  569.9843522815 | Norm:   24.1955088912\n",
      "Layer: blocks.0.ln1                             | Shape: torch.Size([1, 6, 192]) | Sum:   -5.1508137006 | Norm:   32.4332542581\n",
      "Layer: blocks.0.sa.heads.0.key                  | Shape: torch.Size([1, 6, 32]) | Sum:   15.2897159308 | Norm:   15.3424885267\n",
      "Layer: blocks.0.sa.heads.0.query                | Shape: torch.Size([1, 6, 32]) | Sum:    8.0905164976 | Norm:    8.9466653851\n",
      "Layer: blocks.0.sa.heads.0.value                | Shape: torch.Size([1, 6, 32]) | Sum:   -3.4559992458 | Norm:    2.9005384412\n",
      "Layer: blocks.0.sa.heads.0.dropout              | Shape: torch.Size([1, 6, 6]) | Sum:    5.9999999404 | Norm:    1.5776431632\n",
      "Layer: blocks.0.sa.heads.0                      | Shape: torch.Size([1, 6, 32]) | Sum:   -3.4671414156 | Norm:    2.2729675092\n",
      "Layer: blocks.0.sa.heads.1.key                  | Shape: torch.Size([1, 6, 32]) | Sum:  -56.8135065991 | Norm:   19.7219889540\n",
      "Layer: blocks.0.sa.heads.1.query                | Shape: torch.Size([1, 6, 32]) | Sum:  -25.4247273849 | Norm:   19.1352875014\n",
      "Layer: blocks.0.sa.heads.1.value                | Shape: torch.Size([1, 6, 32]) | Sum:   -2.1440495998 | Norm:    2.2547662196\n",
      "Layer: blocks.0.sa.heads.1.dropout              | Shape: torch.Size([1, 6, 6]) | Sum:    5.9999999516 | Norm:    1.6987268773\n",
      "Layer: blocks.0.sa.heads.1                      | Shape: torch.Size([1, 6, 32]) | Sum:   -1.9650424094 | Norm:    1.5247337602\n",
      "Layer: blocks.0.sa.heads.2.key                  | Shape: torch.Size([1, 6, 32]) | Sum:    9.1241606066 | Norm:   16.5079376863\n",
      "Layer: blocks.0.sa.heads.2.query                | Shape: torch.Size([1, 6, 32]) | Sum:   33.8773787301 | Norm:   15.6912279481\n",
      "Layer: blocks.0.sa.heads.2.value                | Shape: torch.Size([1, 6, 32]) | Sum:   -2.9179258918 | Norm:    2.8045036971\n",
      "Layer: blocks.0.sa.heads.2.dropout              | Shape: torch.Size([1, 6, 6]) | Sum:    6.0000000745 | Norm:    1.7097774686\n",
      "Layer: blocks.0.sa.heads.2                      | Shape: torch.Size([1, 6, 32]) | Sum:   -6.0176424009 | Norm:    2.3260106401\n",
      "Layer: blocks.0.sa.heads.3.key                  | Shape: torch.Size([1, 6, 32]) | Sum:    3.8225465585 | Norm:   18.4183651408\n",
      "Layer: blocks.0.sa.heads.3.query                | Shape: torch.Size([1, 6, 32]) | Sum:  -19.7685965588 | Norm:   13.0310224606\n",
      "Layer: blocks.0.sa.heads.3.value                | Shape: torch.Size([1, 6, 32]) | Sum:    0.0316566184 | Norm:    2.6398362010\n",
      "Layer: blocks.0.sa.heads.3.dropout              | Shape: torch.Size([1, 6, 6]) | Sum:    6.0000000373 | Norm:    1.6741020226\n",
      "Layer: blocks.0.sa.heads.3                      | Shape: torch.Size([1, 6, 32]) | Sum:   -0.2346565323 | Norm:    2.3489115160\n",
      "Layer: blocks.0.sa.heads.4.key                  | Shape: torch.Size([1, 6, 32]) | Sum:   40.6650871262 | Norm:   23.3968333477\n",
      "Layer: blocks.0.sa.heads.4.query                | Shape: torch.Size([1, 6, 32]) | Sum:  -29.2300072834 | Norm:   16.0010104465\n",
      "Layer: blocks.0.sa.heads.4.value                | Shape: torch.Size([1, 6, 32]) | Sum:   -0.4735261053 | Norm:    2.6534419746\n",
      "Layer: blocks.0.sa.heads.4.dropout              | Shape: torch.Size([1, 6, 6]) | Sum:    6.0000000969 | Norm:    1.6818943308\n",
      "Layer: blocks.0.sa.heads.4                      | Shape: torch.Size([1, 6, 32]) | Sum:    1.4252266920 | Norm:    2.0083223720\n",
      "Layer: blocks.0.sa.heads.5.key                  | Shape: torch.Size([1, 6, 32]) | Sum:   14.4425024129 | Norm:   19.0758422738\n",
      "Layer: blocks.0.sa.heads.5.query                | Shape: torch.Size([1, 6, 32]) | Sum:  -17.4355439432 | Norm:   15.4505947192\n",
      "Layer: blocks.0.sa.heads.5.value                | Shape: torch.Size([1, 6, 32]) | Sum:   -4.7470799375 | Norm:    2.5668157693\n",
      "Layer: blocks.0.sa.heads.5.dropout              | Shape: torch.Size([1, 6, 6]) | Sum:    5.9999999851 | Norm:    1.6197737997\n",
      "Layer: blocks.0.sa.heads.5                      | Shape: torch.Size([1, 6, 32]) | Sum:   -2.2695849354 | Norm:    1.9423673847\n",
      "Layer: blocks.0.sa.proj                         | Shape: torch.Size([1, 6, 192]) | Sum:  -32.1161236927 | Norm:    3.7456689305\n",
      "Layer: blocks.0.sa.dropout                      | Shape: torch.Size([1, 6, 192]) | Sum:  -32.1161236927 | Norm:    3.7456689305\n",
      "Layer: blocks.0.sa                              | Shape: torch.Size([1, 6, 192]) | Sum:  -32.1161236927 | Norm:    3.7456689305\n",
      "Layer: blocks.0.ln2                             | Shape: torch.Size([1, 6, 192]) | Sum:  -28.9568522042 | Norm:   32.1198937753\n",
      "Layer: blocks.0.ffwd.net.0                      | Shape: torch.Size([1, 6, 768]) | Sum: -114.3872246936 | Norm:   25.4449079854\n",
      "Layer: blocks.0.ffwd.net.1                      | Shape: torch.Size([1, 6, 768]) | Sum:  172.4226720496 | Norm:   12.8160940906\n",
      "Layer: blocks.0.ffwd.net.2                      | Shape: torch.Size([1, 6, 192]) | Sum:   -6.6245301547 | Norm:    9.8521780714\n",
      "Layer: blocks.0.ffwd.net.3                      | Shape: torch.Size([1, 6, 192]) | Sum:   -6.6245301547 | Norm:    9.8521780714\n",
      "Layer: blocks.0.ffwd.net                        | Shape: torch.Size([1, 6, 192]) | Sum:   -6.6245301547 | Norm:    9.8521780714\n",
      "Layer: blocks.0.ffwd                            | Shape: torch.Size([1, 6, 192]) | Sum:   -6.6245301547 | Norm:    9.8521780714\n",
      "Layer: blocks.0                                 | Shape: torch.Size([1, 6, 192]) | Sum:  531.2436982850 | Norm:   25.6433995859\n",
      "Layer: blocks.1.ln1                             | Shape: torch.Size([1, 6, 192]) | Sum:   -5.1820840305 | Norm:   33.0981176978\n",
      "Layer: blocks.1.sa.heads.0.key                  | Shape: torch.Size([1, 6, 32]) | Sum:   -3.9391923696 | Norm:   12.8029884383\n",
      "Layer: blocks.1.sa.heads.0.query                | Shape: torch.Size([1, 6, 32]) | Sum:   21.3212052481 | Norm:   10.2044568117\n",
      "Layer: blocks.1.sa.heads.0.value                | Shape: torch.Size([1, 6, 32]) | Sum:   -0.2219145843 | Norm:    5.4482862380\n",
      "Layer: blocks.1.sa.heads.0.dropout              | Shape: torch.Size([1, 6, 6]) | Sum:    6.0000000820 | Norm:    1.6961851484\n",
      "Layer: blocks.1.sa.heads.0                      | Shape: torch.Size([1, 6, 32]) | Sum:   -6.0647213708 | Norm:    1.7775960919\n",
      "Layer: blocks.1.sa.heads.1.key                  | Shape: torch.Size([1, 6, 32]) | Sum:   11.5452925297 | Norm:   14.0366515737\n",
      "Layer: blocks.1.sa.heads.1.query                | Shape: torch.Size([1, 6, 32]) | Sum:  -19.1737765783 | Norm:   14.3882763433\n",
      "Layer: blocks.1.sa.heads.1.value                | Shape: torch.Size([1, 6, 32]) | Sum:   -0.1462510992 | Norm:    4.6127047680\n",
      "Layer: blocks.1.sa.heads.1.dropout              | Shape: torch.Size([1, 6, 6]) | Sum:    5.9999999441 | Norm:    1.6199672322\n",
      "Layer: blocks.1.sa.heads.1                      | Shape: torch.Size([1, 6, 32]) | Sum:   -3.0095589592 | Norm:    3.3186756880\n",
      "Layer: blocks.1.sa.heads.2.key                  | Shape: torch.Size([1, 6, 32]) | Sum:  -14.9175324980 | Norm:   21.2756582995\n",
      "Layer: blocks.1.sa.heads.2.query                | Shape: torch.Size([1, 6, 32]) | Sum:  -21.5402185871 | Norm:   14.1971294713\n",
      "Layer: blocks.1.sa.heads.2.value                | Shape: torch.Size([1, 6, 32]) | Sum:    2.0072806595 | Norm:    4.9725732808\n",
      "Layer: blocks.1.sa.heads.2.dropout              | Shape: torch.Size([1, 6, 6]) | Sum:    5.9999999963 | Norm:    1.7201846994\n",
      "Layer: blocks.1.sa.heads.2                      | Shape: torch.Size([1, 6, 32]) | Sum:   -3.0906151703 | Norm:    3.0402549125\n",
      "Layer: blocks.1.sa.heads.3.key                  | Shape: torch.Size([1, 6, 32]) | Sum:  -12.0222205482 | Norm:   17.0187099336\n",
      "Layer: blocks.1.sa.heads.3.query                | Shape: torch.Size([1, 6, 32]) | Sum:  -46.3319585256 | Norm:   13.5012757353\n",
      "Layer: blocks.1.sa.heads.3.value                | Shape: torch.Size([1, 6, 32]) | Sum:    1.1237703047 | Norm:    3.9020774919\n",
      "Layer: blocks.1.sa.heads.3.dropout              | Shape: torch.Size([1, 6, 6]) | Sum:    5.9999999404 | Norm:    1.6201486726\n",
      "Layer: blocks.1.sa.heads.3                      | Shape: torch.Size([1, 6, 32]) | Sum:   -4.2421651839 | Norm:    3.1635162671\n",
      "Layer: blocks.1.sa.heads.4.key                  | Shape: torch.Size([1, 6, 32]) | Sum:   44.0252676513 | Norm:   18.8159610988\n",
      "Layer: blocks.1.sa.heads.4.query                | Shape: torch.Size([1, 6, 32]) | Sum:   37.2942934555 | Norm:   12.7773993445\n",
      "Layer: blocks.1.sa.heads.4.value                | Shape: torch.Size([1, 6, 32]) | Sum:    3.9989041362 | Norm:    4.9569685988\n",
      "Layer: blocks.1.sa.heads.4.dropout              | Shape: torch.Size([1, 6, 6]) | Sum:    5.9999998994 | Norm:    1.7486250394\n",
      "Layer: blocks.1.sa.heads.4                      | Shape: torch.Size([1, 6, 32]) | Sum:    4.3139955137 | Norm:    3.6829870795\n",
      "Layer: blocks.1.sa.heads.5.key                  | Shape: torch.Size([1, 6, 32]) | Sum:  -15.6476588333 | Norm:   17.8106740338\n",
      "Layer: blocks.1.sa.heads.5.query                | Shape: torch.Size([1, 6, 32]) | Sum:  -14.4908173881 | Norm:   17.0646490886\n",
      "Layer: blocks.1.sa.heads.5.value                | Shape: torch.Size([1, 6, 32]) | Sum:   19.7733817371 | Norm:    5.0359177750\n",
      "Layer: blocks.1.sa.heads.5.dropout              | Shape: torch.Size([1, 6, 6]) | Sum:    6.0000001080 | Norm:    1.7101443068\n",
      "Layer: blocks.1.sa.heads.5                      | Shape: torch.Size([1, 6, 32]) | Sum:   20.0031436887 | Norm:    4.1323193790\n",
      "Layer: blocks.1.sa.proj                         | Shape: torch.Size([1, 6, 192]) | Sum:    8.1864163047 | Norm:    6.4068308206\n",
      "Layer: blocks.1.sa.dropout                      | Shape: torch.Size([1, 6, 192]) | Sum:    8.1864163047 | Norm:    6.4068308206\n",
      "Layer: blocks.1.sa                              | Shape: torch.Size([1, 6, 192]) | Sum:    8.1864163047 | Norm:    6.4068308206\n",
      "Layer: blocks.1.ln2                             | Shape: torch.Size([1, 6, 192]) | Sum:  -13.7405948285 | Norm:   33.4448701979\n",
      "Layer: blocks.1.ffwd.net.0                      | Shape: torch.Size([1, 6, 768]) | Sum: -743.8319137311 | Norm:   35.4335302412\n",
      "Layer: blocks.1.ffwd.net.1                      | Shape: torch.Size([1, 6, 768]) | Sum:   46.6851166933 | Norm:   14.6534313198\n",
      "Layer: blocks.1.ffwd.net.2                      | Shape: torch.Size([1, 6, 192]) | Sum:    3.4403487182 | Norm:    8.8523207823\n",
      "Layer: blocks.1.ffwd.net.3                      | Shape: torch.Size([1, 6, 192]) | Sum:    3.4403487182 | Norm:    8.8523207823\n",
      "Layer: blocks.1.ffwd.net                        | Shape: torch.Size([1, 6, 192]) | Sum:    3.4403487182 | Norm:    8.8523207823\n",
      "Layer: blocks.1.ffwd                            | Shape: torch.Size([1, 6, 192]) | Sum:    3.4403487182 | Norm:    8.8523207823\n",
      "Layer: blocks.1                                 | Shape: torch.Size([1, 6, 192]) | Sum:  542.8704622118 | Norm:   32.1902222969\n",
      "Layer: blocks.2.ln1                             | Shape: torch.Size([1, 6, 192]) | Sum:   -4.5410224684 | Norm:   34.0362392424\n",
      "Layer: blocks.2.sa.heads.0.key                  | Shape: torch.Size([1, 6, 32]) | Sum:  -15.8309740688 | Norm:   15.9940848098\n",
      "Layer: blocks.2.sa.heads.0.query                | Shape: torch.Size([1, 6, 32]) | Sum:   76.6018293016 | Norm:   11.9949651733\n",
      "Layer: blocks.2.sa.heads.0.value                | Shape: torch.Size([1, 6, 32]) | Sum:    8.6714733057 | Norm:    5.9731051562\n",
      "Layer: blocks.2.sa.heads.0.dropout              | Shape: torch.Size([1, 6, 6]) | Sum:    6.0000000112 | Norm:    1.6810789744\n",
      "Layer: blocks.2.sa.heads.0                      | Shape: torch.Size([1, 6, 32]) | Sum:    2.8991511920 | Norm:    2.7492024679\n",
      "Layer: blocks.2.sa.heads.1.key                  | Shape: torch.Size([1, 6, 32]) | Sum:    4.3318523824 | Norm:   11.8782107431\n",
      "Layer: blocks.2.sa.heads.1.query                | Shape: torch.Size([1, 6, 32]) | Sum: -113.5814524870 | Norm:   19.3220997005\n",
      "Layer: blocks.2.sa.heads.1.value                | Shape: torch.Size([1, 6, 32]) | Sum:   -0.9184052401 | Norm:    7.7553336404\n",
      "Layer: blocks.2.sa.heads.1.dropout              | Shape: torch.Size([1, 6, 6]) | Sum:    6.0000000745 | Norm:    1.8176158865\n",
      "Layer: blocks.2.sa.heads.1                      | Shape: torch.Size([1, 6, 32]) | Sum:    8.1942495657 | Norm:    6.2659812476\n",
      "Layer: blocks.2.sa.heads.2.key                  | Shape: torch.Size([1, 6, 32]) | Sum:  -31.5346455052 | Norm:   22.7204327438\n",
      "Layer: blocks.2.sa.heads.2.query                | Shape: torch.Size([1, 6, 32]) | Sum:  -43.9676598776 | Norm:   20.6773914057\n",
      "Layer: blocks.2.sa.heads.2.value                | Shape: torch.Size([1, 6, 32]) | Sum:   -6.9224904482 | Norm:    4.7588948506\n",
      "Layer: blocks.2.sa.heads.2.dropout              | Shape: torch.Size([1, 6, 6]) | Sum:    6.0000000233 | Norm:    1.8727094805\n",
      "Layer: blocks.2.sa.heads.2                      | Shape: torch.Size([1, 6, 32]) | Sum:   -6.0164732555 | Norm:    3.6622832649\n",
      "Layer: blocks.2.sa.heads.3.key                  | Shape: torch.Size([1, 6, 32]) | Sum:   55.2082353165 | Norm:   12.4712681242\n",
      "Layer: blocks.2.sa.heads.3.query                | Shape: torch.Size([1, 6, 32]) | Sum:   -3.8431059700 | Norm:   11.9945234121\n",
      "Layer: blocks.2.sa.heads.3.value                | Shape: torch.Size([1, 6, 32]) | Sum:   15.3748405604 | Norm:    8.5159380051\n",
      "Layer: blocks.2.sa.heads.3.dropout              | Shape: torch.Size([1, 6, 6]) | Sum:    5.9999998063 | Norm:    1.5708078268\n",
      "Layer: blocks.2.sa.heads.3                      | Shape: torch.Size([1, 6, 32]) | Sum:    4.5846488387 | Norm:    5.9354962482\n",
      "Layer: blocks.2.sa.heads.4.key                  | Shape: torch.Size([1, 6, 32]) | Sum:  -28.6617868616 | Norm:   23.7558800901\n",
      "Layer: blocks.2.sa.heads.4.query                | Shape: torch.Size([1, 6, 32]) | Sum:    5.5014812294 | Norm:   11.9992405242\n",
      "Layer: blocks.2.sa.heads.4.value                | Shape: torch.Size([1, 6, 32]) | Sum:    0.9686643372 | Norm:    6.3054640316\n",
      "Layer: blocks.2.sa.heads.4.dropout              | Shape: torch.Size([1, 6, 6]) | Sum:    5.9999999144 | Norm:    1.9269706404\n",
      "Layer: blocks.2.sa.heads.4                      | Shape: torch.Size([1, 6, 32]) | Sum:   -7.6399592224 | Norm:    3.8392124033\n",
      "Layer: blocks.2.sa.heads.5.key                  | Shape: torch.Size([1, 6, 32]) | Sum:  -11.8914284609 | Norm:   12.8315642945\n",
      "Layer: blocks.2.sa.heads.5.query                | Shape: torch.Size([1, 6, 32]) | Sum:   12.3608498550 | Norm:   12.9854690676\n",
      "Layer: blocks.2.sa.heads.5.value                | Shape: torch.Size([1, 6, 32]) | Sum:  -17.6736850164 | Norm:    5.6582007580\n",
      "Layer: blocks.2.sa.heads.5.dropout              | Shape: torch.Size([1, 6, 6]) | Sum:    5.9999999944 | Norm:    1.7746807559\n",
      "Layer: blocks.2.sa.heads.5                      | Shape: torch.Size([1, 6, 32]) | Sum:  -13.1572545540 | Norm:    2.3773514665\n",
      "Layer: blocks.2.sa.proj                         | Shape: torch.Size([1, 6, 192]) | Sum:   13.2145110117 | Norm:    6.0977839175\n",
      "Layer: blocks.2.sa.dropout                      | Shape: torch.Size([1, 6, 192]) | Sum:   13.2145110117 | Norm:    6.0977839175\n",
      "Layer: blocks.2.sa                              | Shape: torch.Size([1, 6, 192]) | Sum:   13.2145110117 | Norm:    6.0977839175\n",
      "Layer: blocks.2.ln2                             | Shape: torch.Size([1, 6, 192]) | Sum:   -1.1524599572 | Norm:   34.5023113293\n",
      "Layer: blocks.2.ffwd.net.0                      | Shape: torch.Size([1, 6, 768]) | Sum: -1198.5247429269 | Norm:   43.7059876339\n",
      "Layer: blocks.2.ffwd.net.1                      | Shape: torch.Size([1, 6, 768]) | Sum:  -17.7346981973 | Norm:   16.0554842608\n",
      "Layer: blocks.2.ffwd.net.2                      | Shape: torch.Size([1, 6, 192]) | Sum:    1.3253427204 | Norm:    8.4767046976\n",
      "Layer: blocks.2.ffwd.net.3                      | Shape: torch.Size([1, 6, 192]) | Sum:    1.3253427204 | Norm:    8.4767046976\n",
      "Layer: blocks.2.ffwd.net                        | Shape: torch.Size([1, 6, 192]) | Sum:    1.3253427204 | Norm:    8.4767046976\n",
      "Layer: blocks.2.ffwd                            | Shape: torch.Size([1, 6, 192]) | Sum:    1.3253427204 | Norm:    8.4767046976\n",
      "Layer: blocks.2                                 | Shape: torch.Size([1, 6, 192]) | Sum:  557.4103150535 | Norm:   37.2128850021\n",
      "Layer: blocks.3.ln1                             | Shape: torch.Size([1, 6, 192]) | Sum:   -4.1111224745 | Norm:   35.3689192794\n",
      "Layer: blocks.3.sa.heads.0.key                  | Shape: torch.Size([1, 6, 32]) | Sum:  102.2486695684 | Norm:   25.9021861178\n",
      "Layer: blocks.3.sa.heads.0.query                | Shape: torch.Size([1, 6, 32]) | Sum:   27.2008212255 | Norm:   17.6331582575\n",
      "Layer: blocks.3.sa.heads.0.value                | Shape: torch.Size([1, 6, 32]) | Sum:    2.5263177650 | Norm:    9.8974746566\n",
      "Layer: blocks.3.sa.heads.0.dropout              | Shape: torch.Size([1, 6, 6]) | Sum:    5.9999998137 | Norm:    1.6796658395\n",
      "Layer: blocks.3.sa.heads.0                      | Shape: torch.Size([1, 6, 32]) | Sum:    2.2902954232 | Norm:    4.0179687969\n",
      "Layer: blocks.3.sa.heads.1.key                  | Shape: torch.Size([1, 6, 32]) | Sum:    9.7015082147 | Norm:   17.4077290554\n",
      "Layer: blocks.3.sa.heads.1.query                | Shape: torch.Size([1, 6, 32]) | Sum:  -21.6331255469 | Norm:   18.5006766224\n",
      "Layer: blocks.3.sa.heads.1.value                | Shape: torch.Size([1, 6, 32]) | Sum:   20.3753913576 | Norm:    9.5525277823\n",
      "Layer: blocks.3.sa.heads.1.dropout              | Shape: torch.Size([1, 6, 6]) | Sum:    6.0000000130 | Norm:    1.8673469130\n",
      "Layer: blocks.3.sa.heads.1                      | Shape: torch.Size([1, 6, 32]) | Sum:    5.1793486048 | Norm:    7.0669303603\n",
      "Layer: blocks.3.sa.heads.2.key                  | Shape: torch.Size([1, 6, 32]) | Sum:   75.8738232031 | Norm:   25.8495274809\n",
      "Layer: blocks.3.sa.heads.2.query                | Shape: torch.Size([1, 6, 32]) | Sum:    7.6288732146 | Norm:   21.0918767018\n",
      "Layer: blocks.3.sa.heads.2.value                | Shape: torch.Size([1, 6, 32]) | Sum:  -20.9065212472 | Norm:    8.8309062779\n",
      "Layer: blocks.3.sa.heads.2.dropout              | Shape: torch.Size([1, 6, 6]) | Sum:    5.9999998244 | Norm:    1.8504470784\n",
      "Layer: blocks.3.sa.heads.2                      | Shape: torch.Size([1, 6, 32]) | Sum:  -17.6458908151 | Norm:    4.3851524637\n",
      "Layer: blocks.3.sa.heads.3.key                  | Shape: torch.Size([1, 6, 32]) | Sum:  151.4645654410 | Norm:   36.8749875030\n",
      "Layer: blocks.3.sa.heads.3.query                | Shape: torch.Size([1, 6, 32]) | Sum:   33.0472171064 | Norm:   22.3480113366\n",
      "Layer: blocks.3.sa.heads.3.value                | Shape: torch.Size([1, 6, 32]) | Sum:   -2.0599570959 | Norm:    6.0693642813\n",
      "Layer: blocks.3.sa.heads.3.dropout              | Shape: torch.Size([1, 6, 6]) | Sum:    5.9999999358 | Norm:    2.2780901038\n",
      "Layer: blocks.3.sa.heads.3                      | Shape: torch.Size([1, 6, 32]) | Sum:   -1.1299084914 | Norm:    3.3362467924\n",
      "Layer: blocks.3.sa.heads.4.key                  | Shape: torch.Size([1, 6, 32]) | Sum:  -24.9328538701 | Norm:   32.1536421753\n",
      "Layer: blocks.3.sa.heads.4.query                | Shape: torch.Size([1, 6, 32]) | Sum:   -9.0876291379 | Norm:   14.6779556392\n",
      "Layer: blocks.3.sa.heads.4.value                | Shape: torch.Size([1, 6, 32]) | Sum:   -4.9689908805 | Norm:    5.5905016789\n",
      "Layer: blocks.3.sa.heads.4.dropout              | Shape: torch.Size([1, 6, 6]) | Sum:    5.9999998142 | Norm:    1.9205135772\n",
      "Layer: blocks.3.sa.heads.4                      | Shape: torch.Size([1, 6, 32]) | Sum:   -4.6035224332 | Norm:    3.4748653627\n",
      "Layer: blocks.3.sa.heads.5.key                  | Shape: torch.Size([1, 6, 32]) | Sum:  -11.5553923994 | Norm:   31.6666759014\n",
      "Layer: blocks.3.sa.heads.5.query                | Shape: torch.Size([1, 6, 32]) | Sum:  -14.7155777141 | Norm:   23.6190338238\n",
      "Layer: blocks.3.sa.heads.5.value                | Shape: torch.Size([1, 6, 32]) | Sum:    8.1914820243 | Norm:    4.8673221800\n",
      "Layer: blocks.3.sa.heads.5.dropout              | Shape: torch.Size([1, 6, 6]) | Sum:    6.0000000256 | Norm:    1.9863598846\n",
      "Layer: blocks.3.sa.heads.5                      | Shape: torch.Size([1, 6, 32]) | Sum:    0.4267350417 | Norm:    3.2204850798\n",
      "Layer: blocks.3.sa.proj                         | Shape: torch.Size([1, 6, 192]) | Sum:   -5.8639902193 | Norm:    5.3130016269\n",
      "Layer: blocks.3.sa.dropout                      | Shape: torch.Size([1, 6, 192]) | Sum:   -5.8639902193 | Norm:    5.3130016269\n",
      "Layer: blocks.3.sa                              | Shape: torch.Size([1, 6, 192]) | Sum:   -5.8639902193 | Norm:    5.3130016269\n",
      "Layer: blocks.3.ln2                             | Shape: torch.Size([1, 6, 192]) | Sum:    4.9157092452 | Norm:   35.9858613369\n",
      "Layer: blocks.3.ffwd.net.0                      | Shape: torch.Size([1, 6, 768]) | Sum: -1392.6668709107 | Norm:   52.3128489026\n",
      "Layer: blocks.3.ffwd.net.1                      | Shape: torch.Size([1, 6, 768]) | Sum:  105.3454959340 | Norm:   18.5302084664\n",
      "Layer: blocks.3.ffwd.net.2                      | Shape: torch.Size([1, 6, 192]) | Sum:    5.6115148477 | Norm:    9.1085670634\n",
      "Layer: blocks.3.ffwd.net.3                      | Shape: torch.Size([1, 6, 192]) | Sum:    5.6115148477 | Norm:    9.1085670634\n",
      "Layer: blocks.3.ffwd.net                        | Shape: torch.Size([1, 6, 192]) | Sum:    5.6115148477 | Norm:    9.1085670634\n",
      "Layer: blocks.3.ffwd                            | Shape: torch.Size([1, 6, 192]) | Sum:    5.6115148477 | Norm:    9.1085670634\n",
      "Layer: blocks.3                                 | Shape: torch.Size([1, 6, 192]) | Sum:  557.1578382663 | Norm:   40.3849462956\n",
      "Layer: blocks.4.ln1                             | Shape: torch.Size([1, 6, 192]) | Sum:   -3.5781248691 | Norm:   36.5463446505\n",
      "Layer: blocks.4.sa.heads.0.key                  | Shape: torch.Size([1, 6, 32]) | Sum:    9.6168573493 | Norm:   27.4634647039\n",
      "Layer: blocks.4.sa.heads.0.query                | Shape: torch.Size([1, 6, 32]) | Sum:   48.9195896508 | Norm:   17.3006922006\n",
      "Layer: blocks.4.sa.heads.0.value                | Shape: torch.Size([1, 6, 32]) | Sum:   -6.6516387139 | Norm:    9.7618712854\n",
      "Layer: blocks.4.sa.heads.0.dropout              | Shape: torch.Size([1, 6, 6]) | Sum:    5.9999999478 | Norm:    1.6473919152\n",
      "Layer: blocks.4.sa.heads.0                      | Shape: torch.Size([1, 6, 32]) | Sum:   -3.4993227639 | Norm:    5.2448997378\n",
      "Layer: blocks.4.sa.heads.1.key                  | Shape: torch.Size([1, 6, 32]) | Sum:   21.6080761775 | Norm:   27.7273699740\n",
      "Layer: blocks.4.sa.heads.1.query                | Shape: torch.Size([1, 6, 32]) | Sum:  -10.4710142706 | Norm:   20.1197688785\n",
      "Layer: blocks.4.sa.heads.1.value                | Shape: torch.Size([1, 6, 32]) | Sum:   14.2820466488 | Norm:   10.7003674218\n",
      "Layer: blocks.4.sa.heads.1.dropout              | Shape: torch.Size([1, 6, 6]) | Sum:    5.9999998361 | Norm:    1.9499517886\n",
      "Layer: blocks.4.sa.heads.1                      | Shape: torch.Size([1, 6, 32]) | Sum:    9.8526904029 | Norm:    8.0671230512\n",
      "Layer: blocks.4.sa.heads.2.key                  | Shape: torch.Size([1, 6, 32]) | Sum:  -19.4401064692 | Norm:   23.2976853860\n",
      "Layer: blocks.4.sa.heads.2.query                | Shape: torch.Size([1, 6, 32]) | Sum:  -35.7498562364 | Norm:   22.0962983130\n",
      "Layer: blocks.4.sa.heads.2.value                | Shape: torch.Size([1, 6, 32]) | Sum:   -9.3771494837 | Norm:    7.7304566779\n",
      "Layer: blocks.4.sa.heads.2.dropout              | Shape: torch.Size([1, 6, 6]) | Sum:    6.0000000170 | Norm:    1.9790255084\n",
      "Layer: blocks.4.sa.heads.2                      | Shape: torch.Size([1, 6, 32]) | Sum:    0.0705391257 | Norm:    4.0595892377\n",
      "Layer: blocks.4.sa.heads.3.key                  | Shape: torch.Size([1, 6, 32]) | Sum:   24.7371782474 | Norm:   25.9018552348\n",
      "Layer: blocks.4.sa.heads.3.query                | Shape: torch.Size([1, 6, 32]) | Sum:   73.6507660444 | Norm:   17.0552334407\n",
      "Layer: blocks.4.sa.heads.3.value                | Shape: torch.Size([1, 6, 32]) | Sum:    5.0298991574 | Norm:    6.8013897034\n",
      "Layer: blocks.4.sa.heads.3.dropout              | Shape: torch.Size([1, 6, 6]) | Sum:    5.9999999460 | Norm:    1.6715757077\n",
      "Layer: blocks.4.sa.heads.3                      | Shape: torch.Size([1, 6, 32]) | Sum:    0.6961566869 | Norm:    4.6743267041\n",
      "Layer: blocks.4.sa.heads.4.key                  | Shape: torch.Size([1, 6, 32]) | Sum:  -67.6202115882 | Norm:   26.0047806872\n",
      "Layer: blocks.4.sa.heads.4.query                | Shape: torch.Size([1, 6, 32]) | Sum:  -15.3273107745 | Norm:   17.4334117381\n",
      "Layer: blocks.4.sa.heads.4.value                | Shape: torch.Size([1, 6, 32]) | Sum:   -8.7461022492 | Norm:    9.8464463848\n",
      "Layer: blocks.4.sa.heads.4.dropout              | Shape: torch.Size([1, 6, 6]) | Sum:    5.9999999329 | Norm:    1.5886879865\n",
      "Layer: blocks.4.sa.heads.4                      | Shape: torch.Size([1, 6, 32]) | Sum:   -0.0354740295 | Norm:    5.9150774430\n",
      "Layer: blocks.4.sa.heads.5.key                  | Shape: torch.Size([1, 6, 32]) | Sum:  -11.0682730060 | Norm:   25.1079836553\n",
      "Layer: blocks.4.sa.heads.5.query                | Shape: torch.Size([1, 6, 32]) | Sum:  -36.3343962628 | Norm:   19.5535760259\n",
      "Layer: blocks.4.sa.heads.5.value                | Shape: torch.Size([1, 6, 32]) | Sum:   -2.6075143906 | Norm:    8.2529023426\n",
      "Layer: blocks.4.sa.heads.5.dropout              | Shape: torch.Size([1, 6, 6]) | Sum:    5.9999999373 | Norm:    1.8793201066\n",
      "Layer: blocks.4.sa.heads.5                      | Shape: torch.Size([1, 6, 32]) | Sum:   13.4693168462 | Norm:    2.8571459731\n",
      "Layer: blocks.4.sa.proj                         | Shape: torch.Size([1, 6, 192]) | Sum:    1.4027374827 | Norm:    9.0038913733\n",
      "Layer: blocks.4.sa.dropout                      | Shape: torch.Size([1, 6, 192]) | Sum:    1.4027374827 | Norm:    9.0038913733\n",
      "Layer: blocks.4.sa                              | Shape: torch.Size([1, 6, 192]) | Sum:    1.4027374827 | Norm:    9.0038913733\n",
      "Layer: blocks.4.ln2                             | Shape: torch.Size([1, 6, 192]) | Sum:    4.4243249791 | Norm:   38.8809495490\n",
      "Layer: blocks.4.ffwd.net.0                      | Shape: torch.Size([1, 6, 768]) | Sum: -2409.8612521174 | Norm:   72.6763169214\n",
      "Layer: blocks.4.ffwd.net.1                      | Shape: torch.Size([1, 6, 768]) | Sum:  165.7782276802 | Norm:   22.8127463689\n",
      "Layer: blocks.4.ffwd.net.2                      | Shape: torch.Size([1, 6, 192]) | Sum:   -9.5916885440 | Norm:   12.7715726222\n",
      "Layer: blocks.4.ffwd.net.3                      | Shape: torch.Size([1, 6, 192]) | Sum:   -9.5916885440 | Norm:   12.7715726222\n",
      "Layer: blocks.4.ffwd.net                        | Shape: torch.Size([1, 6, 192]) | Sum:   -9.5916885440 | Norm:   12.7715726222\n",
      "Layer: blocks.4.ffwd                            | Shape: torch.Size([1, 6, 192]) | Sum:   -9.5916885440 | Norm:   12.7715726222\n",
      "Layer: blocks.4                                 | Shape: torch.Size([1, 6, 192]) | Sum:  548.9688902572 | Norm:   43.7168252589\n",
      "Layer: blocks.5.ln1                             | Shape: torch.Size([1, 6, 192]) | Sum:   -2.2375037321 | Norm:   36.4562808612\n",
      "Layer: blocks.5.sa.heads.0.key                  | Shape: torch.Size([1, 6, 32]) | Sum:   31.2250794978 | Norm:   26.6356599701\n",
      "Layer: blocks.5.sa.heads.0.query                | Shape: torch.Size([1, 6, 32]) | Sum:  -13.2682908382 | Norm:   18.3921533890\n",
      "Layer: blocks.5.sa.heads.0.value                | Shape: torch.Size([1, 6, 32]) | Sum:  -15.4663277102 | Norm:    9.7879773114\n",
      "Layer: blocks.5.sa.heads.0.dropout              | Shape: torch.Size([1, 6, 6]) | Sum:    6.0000000186 | Norm:    1.6627014206\n",
      "Layer: blocks.5.sa.heads.0                      | Shape: torch.Size([1, 6, 32]) | Sum:  -10.4161675565 | Norm:    7.3197004591\n",
      "Layer: blocks.5.sa.heads.1.key                  | Shape: torch.Size([1, 6, 32]) | Sum:  -49.7286264338 | Norm:   19.9289868015\n",
      "Layer: blocks.5.sa.heads.1.query                | Shape: torch.Size([1, 6, 32]) | Sum:    6.8157043578 | Norm:   15.6060021895\n",
      "Layer: blocks.5.sa.heads.1.value                | Shape: torch.Size([1, 6, 32]) | Sum:  -15.9173414810 | Norm:    9.6864146687\n",
      "Layer: blocks.5.sa.heads.1.dropout              | Shape: torch.Size([1, 6, 6]) | Sum:    5.9999999981 | Norm:    1.7030281018\n",
      "Layer: blocks.5.sa.heads.1                      | Shape: torch.Size([1, 6, 32]) | Sum:  -11.4210953582 | Norm:    7.4202485614\n",
      "Layer: blocks.5.sa.heads.2.key                  | Shape: torch.Size([1, 6, 32]) | Sum:  -39.3562419289 | Norm:   17.6417075495\n",
      "Layer: blocks.5.sa.heads.2.query                | Shape: torch.Size([1, 6, 32]) | Sum:  -41.7778345401 | Norm:   13.8008571489\n",
      "Layer: blocks.5.sa.heads.2.value                | Shape: torch.Size([1, 6, 32]) | Sum:   10.9665181051 | Norm:    8.0957732266\n",
      "Layer: blocks.5.sa.heads.2.dropout              | Shape: torch.Size([1, 6, 6]) | Sum:    6.0000000363 | Norm:    2.0585373426\n",
      "Layer: blocks.5.sa.heads.2                      | Shape: torch.Size([1, 6, 32]) | Sum:   10.5263690412 | Norm:    4.1934933699\n",
      "Layer: blocks.5.sa.heads.3.key                  | Shape: torch.Size([1, 6, 32]) | Sum:   77.9242653623 | Norm:   15.0801994033\n",
      "Layer: blocks.5.sa.heads.3.query                | Shape: torch.Size([1, 6, 32]) | Sum:   48.1706497939 | Norm:   14.5867131268\n",
      "Layer: blocks.5.sa.heads.3.value                | Shape: torch.Size([1, 6, 32]) | Sum:   -6.5888663339 | Norm:   13.4483075488\n",
      "Layer: blocks.5.sa.heads.3.dropout              | Shape: torch.Size([1, 6, 6]) | Sum:    6.0000000820 | Norm:    1.6674670628\n",
      "Layer: blocks.5.sa.heads.3                      | Shape: torch.Size([1, 6, 32]) | Sum:  -11.9459957199 | Norm:    7.6055573314\n",
      "Layer: blocks.5.sa.heads.4.key                  | Shape: torch.Size([1, 6, 32]) | Sum:   63.9705184735 | Norm:   21.4568863909\n",
      "Layer: blocks.5.sa.heads.4.query                | Shape: torch.Size([1, 6, 32]) | Sum:   28.2771551143 | Norm:   15.0913440586\n",
      "Layer: blocks.5.sa.heads.4.value                | Shape: torch.Size([1, 6, 32]) | Sum:  -20.0558243468 | Norm:    7.7966490890\n",
      "Layer: blocks.5.sa.heads.4.dropout              | Shape: torch.Size([1, 6, 6]) | Sum:    6.0000002020 | Norm:    1.9082266269\n",
      "Layer: blocks.5.sa.heads.4                      | Shape: torch.Size([1, 6, 32]) | Sum:    1.1689921728 | Norm:    3.5491931444\n",
      "Layer: blocks.5.sa.heads.5.key                  | Shape: torch.Size([1, 6, 32]) | Sum:  -62.8758282061 | Norm:   21.1779706249\n",
      "Layer: blocks.5.sa.heads.5.query                | Shape: torch.Size([1, 6, 32]) | Sum:   -7.4229861954 | Norm:   13.7819057196\n",
      "Layer: blocks.5.sa.heads.5.value                | Shape: torch.Size([1, 6, 32]) | Sum:    0.8497821540 | Norm:   10.7466797473\n",
      "Layer: blocks.5.sa.heads.5.dropout              | Shape: torch.Size([1, 6, 6]) | Sum:    6.0000000224 | Norm:    1.6461098180\n",
      "Layer: blocks.5.sa.heads.5                      | Shape: torch.Size([1, 6, 32]) | Sum:   -4.7323468972 | Norm:    7.0397579225\n",
      "Layer: blocks.5.sa.proj                         | Shape: torch.Size([1, 6, 192]) | Sum:    7.7223005295 | Norm:   11.4976536886\n",
      "Layer: blocks.5.sa.dropout                      | Shape: torch.Size([1, 6, 192]) | Sum:    7.7223005295 | Norm:   11.4976536886\n",
      "Layer: blocks.5.sa                              | Shape: torch.Size([1, 6, 192]) | Sum:    7.7223005295 | Norm:   11.4976536886\n",
      "Layer: blocks.5.ln2                             | Shape: torch.Size([1, 6, 192]) | Sum:    1.2857222911 | Norm:   40.8918859323\n",
      "Layer: blocks.5.ffwd.net.0                      | Shape: torch.Size([1, 6, 768]) | Sum: -3021.6195013532 | Norm:   88.3187663829\n",
      "Layer: blocks.5.ffwd.net.1                      | Shape: torch.Size([1, 6, 768]) | Sum:  341.6727970387 | Norm:   28.7165462172\n",
      "Layer: blocks.5.ffwd.net.2                      | Shape: torch.Size([1, 6, 192]) | Sum:    7.5609060423 | Norm:   18.1770912210\n",
      "Layer: blocks.5.ffwd.net.3                      | Shape: torch.Size([1, 6, 192]) | Sum:    7.5609060423 | Norm:   18.1770912210\n",
      "Layer: blocks.5.ffwd.net                        | Shape: torch.Size([1, 6, 192]) | Sum:    7.5609060423 | Norm:   18.1770912210\n",
      "Layer: blocks.5.ffwd                            | Shape: torch.Size([1, 6, 192]) | Sum:    7.5609060423 | Norm:   18.1770912210\n",
      "Layer: blocks.5                                 | Shape: torch.Size([1, 6, 192]) | Sum:  564.2521001771 | Norm:   46.7588038299\n",
      "Layer: ln_f                                     | Shape: torch.Size([1, 6, 192]) | Sum:   -5.0476792902 | Norm:   48.3325850254\n",
      "Layer: lm_head                                  | Shape: torch.Size([1, 6, 3266]) | Sum: -39812.9835433676 | Norm:  369.6936492972\n",
      "Layer:                                          | Shape: torch.Size([1, 6, 3266]) | Sum: -39812.9835433676 | Norm:  369.6936492972\n",
      "\n",
      "================================================================================\n",
      "Total layers with activations captured: 257\n",
      "================================================================================\n",
      "All 264 hooks removed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Hook System for tiny_transformer - exactly like the example\n",
    "prompt = \"this morning i walk\"\n",
    "\n",
    "# Set model to evaluation mode\n",
    "tiny_transformer.eval()\n",
    "\n",
    "# Encode the prompt\n",
    "prompt_ids = tokenizer.encode(prompt, add_special_tokens=True)\n",
    "\n",
    "# Convert to tensor and add batch dimension\n",
    "input_ids = torch.tensor(prompt_ids, dtype=torch.long).unsqueeze(0)  # Shape: [1, seq_len]\n",
    "\n",
    "# Move to device if using GPU\n",
    "device = next(tiny_transformer.parameters()).device\n",
    "input_ids = input_ids.to(device)\n",
    "\n",
    "# Define a dictionary to store the outputs\n",
    "activations = {}\n",
    "\n",
    "# Define a hook function\n",
    "def get_hook(name):\n",
    "    def hook_fn(module, input, output):\n",
    "        activations[name] = output\n",
    "    return hook_fn\n",
    "\n",
    "# Register hooks for all layers\n",
    "hooks = []\n",
    "for name, layer in tiny_transformer.named_modules():\n",
    "    hooks.append(layer.register_forward_hook(get_hook(name)))\n",
    "\n",
    "print(f\"Registered {len(hooks)} hooks on all layers\")\n",
    "print(f\"Input shape: {input_ids.shape}\")\n",
    "\n",
    "# Run the forward pass\n",
    "tiny_transformer.eval()\n",
    "with torch.no_grad():\n",
    "    out = tiny_transformer(input_ids)\n",
    "\n",
    "print(f\"Model output shape: {out.shape}\")\n",
    "print(f\"Model output sum: {torch.sum(out)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LAYER ACTIVATIONS ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Access the stored outputs\n",
    "for name, activation in activations.items():\n",
    "    try:\n",
    "        if isinstance(activation, torch.Tensor):\n",
    "            print(f\"Layer: {name:40s} | Shape: {str(activation.shape):20s} | Sum: {torch.sum(activation.to(dtype=torch.float64)):15.10f} | Norm: {torch.norm(activation.to(dtype=torch.float64)):15.10f}\")\n",
    "        else:\n",
    "            print(f\"Layer: {name:40s} | Type: {type(activation).__name__:20s} | Content: {str(activation)[:50]}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Layer: {name:40s} | Error: {str(e)[:50]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Total layers with activations captured: {len([a for a in activations.values() if isinstance(a, torch.Tensor)])}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Remove the hooks\n",
    "for hook in hooks:\n",
    "    hook.remove()\n",
    "    \n",
    "print(f\"All {len(hooks)} hooks removed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fe5efc7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tiny_transformer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m tiny_transformer\u001b[38;5;241m.\u001b[39mnamed_parameters():\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;241m0\u001b[39m,:\u001b[38;5;241m10\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tiny_transformer' is not defined"
     ]
    }
   ],
   "source": [
    "for name, param in tiny_transformer.named_parameters():\n",
    "    print(f\"{name}: {param.data[0,:10]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693bda98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd3d9dd-b430-4604-bc59-1ea423b38b59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc6f762",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ec071b-655f-4d83-a114-abdc99606f91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babeb307-2b5d-428d-af5d-201120386671",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592b6106-3b05-4b34-91b0-4e65a542a7c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578704f2-001f-411b-8a00-626e615412a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94573253-3c7d-45c4-9a02-8d7888682bd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a72b2fb-ad2d-495b-a4f6-74b02b5b4863",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
